{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gensim\n",
    "import re\n",
    "import string\n",
    "import numpy as np\n",
    "import sklearn.neighbors\n",
    "import sklearn.svm\n",
    "\n",
    "w2v_model = gensim.models.KeyedVectors.load_word2vec_format(os.path.join('.', 'models', 'ubercorpus.lowercased.tokenized.word2vec.300d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(doc):\n",
    "    doc = doc.lower()\n",
    "    doc = re.sub('[%s]' % re.escape(string.punctuation), '', doc)\n",
    "    return doc\n",
    "\n",
    "def word_filter(word):\n",
    "    return len(word) >= 4 and word in w2v_model.vocab\n",
    "#     return word in w2v_model.vocab\n",
    "\n",
    "def docs_dataset(dirpath):\n",
    "    for (dirpath, dirnames, filenames) in os.walk(dirpath):\n",
    "        files = filenames\n",
    "        break\n",
    "   \n",
    "    docs = []\n",
    "    for fn in files:\n",
    "        with open(os.path.join(dirpath, fn), 'r', encoding='UTF-8') as f:\n",
    "            line = f.read()\n",
    "            words = normalize(line).split()\n",
    "            words = list(filter(word_filter, words))\n",
    "            if words:\n",
    "                docs.append(words)\n",
    "    return docs\n",
    "    \n",
    "def doc_max_len(docs):\n",
    "    return max(map(len, docs))\n",
    "        \n",
    "def array_assign_2d(a, b):\n",
    "    a[:b.shape[-2], :b.shape[-1]] = b\n",
    "\n",
    "def docs_to_vectors(docs, doc_max_len):\n",
    "    vector_len = w2v_model.vectors.shape[-1]\n",
    "    vectors = np.zeros((len(docs), doc_max_len, vector_len))\n",
    "    for i, doc in enumerate(docs):\n",
    "        doc_vector = w2v_model[doc]\n",
    "        array_assign_2d(vectors[i], doc_vector)\n",
    "    return vectors\n",
    "\n",
    "def shuffle_split(src, fraction):\n",
    "    copy = np.array(src)\n",
    "    np.random.shuffle(copy)\n",
    "    a = copy[:int(copy.shape[0] * fraction)]\n",
    "    b = copy[int(copy.shape[0] * fraction):]\n",
    "    return a, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "phones_path = os.path.join('.', 'data', 'dscr_phones')\n",
    "headphones_path = os.path.join('.', 'data', 'dscr_headphones')\n",
    "tablets_path = os.path.join('.', 'data', 'dscr_tablets')\n",
    "phones_docs = docs_dataset(phones_path)\n",
    "headphones_docs = docs_dataset(headphones_path)\n",
    "tablets_docs = docs_dataset(tablets_path)\n",
    "\n",
    "doc_len = max(doc_max_len(phones_docs), doc_max_len(headphones_docs), doc_max_len(tablets_docs))\n",
    "x_phones = docs_to_vectors(phones_docs, doc_len)\n",
    "x_headphones = docs_to_vectors(headphones_docs, doc_len)\n",
    "x_tablets = docs_to_vectors(tablets_docs, doc_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_phones, x_test_phones = shuffle_split(x_phones, 0.8)\n",
    "x_train_headphones, x_test_headphones = shuffle_split(x_headphones, 0.8)\n",
    "x_train_tablets, x_test_tablets = shuffle_split(x_tablets, 0.8)\n",
    "\n",
    "x_train = np.vstack((x_train_phones, x_train_headphones, x_train_tablets))\n",
    "x_test = np.vstack((x_test_phones, x_test_headphones, x_test_tablets))\n",
    "\n",
    "y_train = np.hstack((\n",
    "    np.full(x_train_phones.shape[0], 1),\n",
    "    np.full(x_train_headphones.shape[0], 2),\n",
    "    np.full(x_train_tablets.shape[0], 3)\n",
    "))\n",
    "y_test = np.hstack((\n",
    "    np.full(x_test_phones.shape[0], 1),\n",
    "    np.full(x_test_headphones.shape[0], 2),\n",
    "    np.full(x_test_tablets.shape[0], 3)\n",
    "))\n",
    "\n",
    "x_train = x_train.mean(axis=1)\n",
    "x_test = x_test.mean(axis=1)\n",
    "# x_train = x_train.reshape((x_train.shape[0], -1))\n",
    "# x_test = x_test.reshape((x_test.shape[0], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished training\n",
      "accuracy = 0.8613445378151261\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[57, 13,  9],\n",
       "       [ 2, 76,  2],\n",
       "       [ 5,  2, 72]], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clf = sklearn.svm.SVC(gamma='scale')\n",
    "clf = sklearn.neighbors.KNeighborsClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "print('finished training')\n",
    "acc = clf.score(x_test, y_test)\n",
    "print('accuracy =', acc)\n",
    "sklearn.metrics.confusion_matrix(y_test, clf.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "538431"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2v_model.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "794"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
